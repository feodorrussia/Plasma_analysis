{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T13:09:46.601598Z",
     "start_time": "2024-09-09T13:09:43.991844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shtRipper v1.3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "from source.NN_environment import normalise_series\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from source.Files_operating import read_sht_data\n",
    "from source.Peaks_processing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.colors import CSS4_COLORS as COLORS\n",
    "\n",
    "colors = ['gold', 'brown', 'black', 'seagreen', 'skyblue', 'cyan', 'yellow', 'violet', 'royalblue', 'sandybrown', 'grey', 'gray', 'indigo', 'rosybrown', 'darkviolet', 'coral', 'pink', 'magenta', 'red', 'springgreen', 'darkblue', 'silver', 'seashell', 'green', 'navy', 'purple', 'sienna', 'chocolate', 'orange', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_signal(arr, N, W):\n",
    "    b, a = signal.butter(N, W)\n",
    "    return signal.filtfilt(b, a, arr)\n",
    "\n",
    "def smooth_rect(y, box_pts):\n",
    "    box = np.ones(box_pts) / box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def smooth_gauss(y, box_pts, sigma=1):\n",
    "    x = np.arange(box_pts) - box_pts / 2\n",
    "    box = 1 / sigma / (2 * np.pi) ** 0.5 * np.exp(-x ** 2 / 2 / sigma ** 2)\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "def smooth_steklov(y, box_pts, ro=0.1):    \n",
    "    c = 1 / 0.4439938161681\n",
    "    x_ro = (np.arange(box_pts) - box_pts / 2) / (box_pts / 2 * ro)\n",
    "    box = np.zeros(box_pts)\n",
    "    box[abs(x_ro) < 1] = 1 / (box_pts / 2 * ro) * c * np.exp(1 / (x_ro[abs(x_ro) < 1] ** 2 - 1))\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T13:10:12.772791Z",
     "start_time": "2024-09-09T13:10:07.640437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>d_alpha</th>\n",
       "      <th>sxr</th>\n",
       "      <th>nl</th>\n",
       "      <th>mhd4</th>\n",
       "      <th>mgd_v</th>\n",
       "      <th>mgd_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.196608</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.104346</td>\n",
       "      <td>22.952502</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>-0.002774</td>\n",
       "      <td>-0.005856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113512</td>\n",
       "      <td>0.437229</td>\n",
       "      <td>0.183266</td>\n",
       "      <td>7.151961</td>\n",
       "      <td>0.171702</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.089512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.334856</td>\n",
       "      <td>-0.135476</td>\n",
       "      <td>-3.010125</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>-5.235000</td>\n",
       "      <td>-4.337791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.098304</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>25.115730</td>\n",
       "      <td>-0.043164</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.010225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.196607</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>25.256830</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>-0.002556</td>\n",
       "      <td>-0.005112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.294911</td>\n",
       "      <td>0.253059</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>26.597276</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.393215</td>\n",
       "      <td>4.828572</td>\n",
       "      <td>2.985586</td>\n",
       "      <td>48.067934</td>\n",
       "      <td>2.598730</td>\n",
       "      <td>5.232444</td>\n",
       "      <td>5.232444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t        d_alpha            sxr             nl  \\\n",
       "count  393216.000000  393216.000000  393216.000000  393216.000000   \n",
       "mean        0.196608       0.208600       0.104346      22.952502   \n",
       "std         0.113512       0.437229       0.183266       7.151961   \n",
       "min         0.000000      -0.334856      -0.135476      -3.010125   \n",
       "25%         0.098304       0.015337       0.025562      25.115730   \n",
       "50%         0.196607       0.043455       0.028118      25.256830   \n",
       "75%         0.294911       0.253059       0.030674      26.597276   \n",
       "max         0.393215       4.828572       2.985586      48.067934   \n",
       "\n",
       "                mhd4          mgd_v          mgd_r  \n",
       "count  393216.000000  393216.000000  393216.000000  \n",
       "mean       -0.007413      -0.002774      -0.005856  \n",
       "std         0.171702       0.070028       0.089512  \n",
       "min        -2.600000      -5.235000      -4.337791  \n",
       "25%        -0.043164      -0.005112      -0.010225  \n",
       "50%        -0.007617      -0.002556      -0.005112  \n",
       "75%         0.027930       0.000000      -0.002556  \n",
       "max         2.598730       5.232444       5.232444  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_ID = 44375\n",
    "proj_path = \"C:/Users/f.belous/Work/Projects/Plasma_analysis\"\n",
    "# D:/Edu/Lab/Projects/Plasma_analysis | C:/Users/f.belous/Work/Projects/Plasma_analysis\n",
    "sht_dir_path = proj_path + \"/data/sht/all/\"  \n",
    "mhd_dir_path = proj_path + \"/data/mhd/\"\n",
    "\n",
    "df = read_sht_data(f'sht{F_ID}', sht_dir_path)\n",
    "df = df.rename(columns={\"ch1\": \"d_alpha\"})\n",
    "df[\"sxr\"] = read_sht_data(f'sht{F_ID}', sht_dir_path, data_name=\"SXR 50 mkm\").ch1\n",
    "df[\"nl\"] = read_sht_data(f'sht{F_ID}', sht_dir_path, data_name=\"nl 42 cm (1.5мм) 64pi\").ch1\n",
    "df[\"mhd4\"] = read_sht_data(f'mhd{F_ID}', mhd_dir_path, data_name=\"МГД4\").ch1\n",
    "\n",
    "# mgd_data_vertical\n",
    "df[\"mgd_v\"] = read_sht_data(f'sht{F_ID}', sht_dir_path, data_name=\"МГД быстрый зонд верт.\").ch1\n",
    "# mgd_data_radial\n",
    "df[\"mgd_r\"] = read_sht_data(f'sht{F_ID}', sht_dir_path, data_name=\"МГД быстрый зонд рад.\").ch1\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T13:10:17.649171Z",
     "start_time": "2024-09-09T13:10:17.628135Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d_alpha = df.d_alpha.to_numpy()\n",
    "sxr = df.sxr.to_numpy()\n",
    "mhd = df.mgd_v.to_numpy() ** 2 + df.mgd_r.to_numpy() ** 2\n",
    "\n",
    "d_alpha_d1 = np.diff(d_alpha)\n",
    "sxr_d1 = np.diff(sxr)\n",
    "\n",
    "d_alpha_f = filt_signal(d_alpha_d1, 5, 0.1)\n",
    "sxr_f = filt_signal(sxr_d1, 5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requested file \"C:/Users/f.belous/Work/Projects/Plasma_analysis/data/dbs/sht/Dref44375.SHT\" does not exist.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ch1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dbs_dir_path \u001b[38;5;241m=\u001b[39m proj_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/dbs/sht/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m dbs_df \u001b[38;5;241m=\u001b[39m read_sht_data(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDref\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mF_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, dbs_dir_path, data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m channels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m channels[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[1;32m~\\Work\\Projects\\Plasma_analysis\\source\\Files_operating.py:72\u001b[0m, in \u001b[0;36mread_sht_data\u001b[1;34m(filename, filepath, data_name)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     res \u001b[38;5;241m=\u001b[39m shtRipper\u001b[38;5;241m.\u001b[39mripper\u001b[38;5;241m.\u001b[39mread(filepath \u001b[38;5;241m+\u001b[39m filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.SHT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([res[data_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], res[data_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m     73\u001b[0m dalpha_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m.\u001b[39mtranspose(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dalpha_df\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ch1'"
     ]
    }
   ],
   "source": [
    "dbs_dir_path = proj_path + \"/data/dbs/sht/\"\n",
    "dbs_df = read_sht_data(f'Dref{F_ID}', dbs_dir_path, data_name=\"ch1\")\n",
    "channels = [1, 2, 3, 4]\n",
    "for i in channels[1:]:\n",
    "    dbs_df[f\"ch{i}\"] = read_sht_data(f'Dref{F_ID}', dbs_dir_path, data_name=f\"ch{i}\").ch1\n",
    "\n",
    "dbs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(1, len(channels) + 1, 2):\n",
    "    w = 0.8\n",
    "    smooth_lenght = 500\n",
    "    i_data = dbs_df[f\"ch{ind}\"].to_numpy() # normalise_series() filt_signal( , 5, w)  smooth_steklov( , smooth_lenght, smooth_lenght / 2)\n",
    "    i_data /= np.linalg.norm(i_data)\n",
    "    q_data = dbs_df[f\"ch{ind + 1}\"].to_numpy()\n",
    "    q_data /= np.linalg.norm(q_data)\n",
    "\n",
    "    c_data = filt_signal(i_data, 5, w) + filt_signal(q_data, 5, w)*1j\n",
    "\n",
    "    fi_data = np.angle(c_data)\n",
    "    # coef = 1\n",
    "    # for i in range(1, fi_data.shape[0]):\n",
    "    #     if q_data[i] * q_data[i - 1] <= 0:\n",
    "    #         coef *= -1\n",
    "    #     fi_data[i] *= coef\n",
    "\n",
    "    dbs_df[f\"ch{ind}_A\"] = smooth_steklov(np.abs(c_data), smooth_lenght, 0.85)\n",
    "    dbs_df[f\"ch{ind}_dfi\"] = smooth_steklov(np.concatenate([np.abs(np.diff(fi_data)), [0]]), smooth_lenght, 0.5)  # np.concatenate([np.diff(), [0]]) smooth_gauss(np.concatenate([filt_signal(np.diff(np.angle(c_data)), 5, w), [0]]), 300)\n",
    "\n",
    "dbs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups_arr = []  # l_edge, r_edge, n, fr, fr_std\n",
    "df_points_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_sxr = Signal_meta(chanel_name=\"sxr\", processing_flag=True)\n",
    "meta_sxr.set_statistics(sxr, sxr_f, 0.8, 0.8, d_std_bottom_edge=7., d_std_top_edge=13.0)\n",
    "meta_sxr.set_edges(length_edge=5, distance_edge=30, scale=0, step_out=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:59:43.298141Z",
     "start_time": "2024-09-09T14:59:42.537753Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mark_data = np.zeros(sxr_f.shape)\n",
    "mark_data[abs(sxr_f - meta_sxr.d_q) > meta_sxr.d_std * meta_sxr.d_std_bottom] = 1\n",
    "mark_sxr = proc_slices(mark_data, sxr, sxr_f, meta_sxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get slices from standart sxr proccessing\n",
    "sxr_slices = get_slices(mark_sxr)  # [Slice(0, 0)] + \n",
    "slices_edges = []\n",
    "step_out = 50\n",
    "\n",
    "len_top = 5000\n",
    "len_width = 3000\n",
    "len_step = 2000\n",
    "\n",
    "# get slices btw sxr falls\n",
    "slices_edges.append([sxr_slices[0].r + step_out, 0])\n",
    "for i in range(1, len(sxr_slices)):\n",
    "    cur_l_edge = slices_edges[-1][0]\n",
    "    while sxr_slices[i].l - step_out - cur_l_edge > len_top:\n",
    "        slices_edges[-1][1] = cur_l_edge + len_width\n",
    "        slices_edges.append([cur_l_edge + len_width, 0])\n",
    "        cur_l_edge += len_step\n",
    "    \n",
    "    slices_edges[-1][1] = sxr_slices[i].l - step_out\n",
    "    slices_edges.append([sxr_slices[i].r + step_out, 0])\n",
    "\n",
    "slices_edges[-1][1] = min(sxr_slices[-1].r + 1000, sxr.shape[0] - step_out)\n",
    "slices_edges = np.array(slices_edges)\n",
    "print(len(slices_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proccess Slice(0, 1st sxr fall)\n",
    "first_slice = Slice(150, sxr_slices[0].l + step_out)\n",
    "print(first_slice)\n",
    "\n",
    "d_alpha_slice = d_alpha[first_slice.l: first_slice.r]\n",
    "d_alpha_f_slice = d_alpha_f[first_slice.l: first_slice.r]\n",
    "\n",
    "meta_da = Signal_meta(chanel_name=\"da\", processing_flag=True)\n",
    "meta_da.set_statistics(d_alpha, d_alpha_f, 0.7, 0.7, d_std_bottom_edge=2., d_std_top_edge=1.0)\n",
    "meta_da.set_edges(length_edge=50, distance_edge=100)\n",
    "\n",
    "mark_data = np.zeros(d_alpha_f_slice.shape)\n",
    "mark_data[abs(d_alpha_f_slice - meta_da.d_q) > meta_da.d_std * meta_da.d_std_bottom] = 1\n",
    "# mark_d_alpha = proc_slices(mark_data, d_alpha_slice, d_alpha_f_slice, meta_da)\n",
    "\n",
    "da_slices = get_slices(mark_data)  # list(filter(lambda x: x.check_length(10), get_slices(mark_d_alpha)))\n",
    "\n",
    "first_slice_edges = []\n",
    "dist_top = 1000\n",
    "step_out = 100\n",
    "\n",
    "first_slice_edges.append([max(0, da_slices[0].l - step_out), da_slices[0].r + step_out])\n",
    "for i in range(len(da_slices)):\n",
    "    if da_slices[i].l - first_slice_edges[-1][1] > dist_top:\n",
    "        first_slice_edges.append([da_slices[i].l - step_out, da_slices[i].l])\n",
    "    elif first_slice_edges[-1][1] - first_slice_edges[-1][0] > len_top:\n",
    "        first_slice_edges.append([first_slice_edges[-1][1] - step_out, first_slice_edges[-1][1]])\n",
    "    first_slice_edges[-1][1] = da_slices[i].r + step_out\n",
    "        \n",
    "\n",
    "first_slice_edges = np.array(first_slice_edges) + 150\n",
    "print(len(first_slice_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_slices_edges = np.concatenate([first_slice_edges, slices_edges]).astype(np.int64)  # slices_edges.astype(np.int64)\n",
    "\n",
    "print(len(res_slices_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_ind = 14  # 0 | 44184 - 9; 44171 - 6; 44172 - 8; 44187 - 6 (4 - syncELM); 44170 - 3\n",
    "bottom_width = 2000\n",
    "\n",
    "for ind in range(start_ind, res_slices_edges.shape[0]):\n",
    "    l_edge, r_edge = res_slices_edges[ind]\n",
    "    plot_l_edge, plot_r_edge = l_edge, r_edge\n",
    "\n",
    "    if plot_r_edge - plot_l_edge < bottom_width:\n",
    "        increasing_d = bottom_width  - (plot_r_edge - plot_l_edge)\n",
    "        plot_l_edge -= increasing_d\n",
    "        plot_r_edge += increasing_d\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=9, gridspec_kw={'hspace': 0.2})  # , sharex=True\n",
    "    \n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(20)\n",
    "    \n",
    "    axs[0].set_title(f\"#{F_ID}\")\n",
    "    \n",
    "    b, a = signal.butter(5, 0.1)\n",
    "    d_alpha_d2f = signal.filtfilt(b, a, np.diff(d_alpha_f))\n",
    "    \n",
    "    axs[0].plot(range(plot_l_edge, plot_r_edge), d_alpha[plot_l_edge:plot_r_edge], label=\"D-alpha\", alpha=0.8, zorder=2)\n",
    "    \n",
    "    # axs[0].plot(range(plot_l_edge, plot_r_edge), d_alpha_f[plot_l_edge:plot_r_edge] * 10, label=\"Filtered D1 (x10)\", alpha=0.8)\n",
    "    # axs[0].plot(range(plot_l_edge, plot_r_edge), d_alpha_d2f[plot_l_edge:plot_r_edge] * 100, label=\"D2 (x100)\", alpha=0.8)\n",
    "    # axs[0].axhline(d_alpha_f.mean(), color=\"red\", linestyle=':', linewidth=0.8)\n",
    "    # axs[0].axhline((d_alpha_f.mean() + d_alpha_f.std()) * 10 * coef, color=\"green\", linestyle=':', linewidth=0.8)\n",
    "    # axs[0].axhline((d_alpha_f.mean() - d_alpha_f.std()) * 10 * coef, color=\"green\", linestyle=':', linewidth=0.8)\n",
    "    # axs[0].axhline((d_alpha_d2f.mean() + d_alpha_d2f.std()) * 100, color=\"blue\", linestyle=':', linewidth=0.8)\n",
    "    # axs[0].axhline((d_alpha_d2f.mean() - d_alpha_d2f.std()) * 100, color=\"blue\", linestyle=':', linewidth=0.8)\n",
    "\n",
    "    \n",
    "    edges_y = (d_alpha[plot_l_edge] + d_alpha[plot_r_edge]) / 2\n",
    "    axs[0].scatter([l_edge, r_edge], [edges_y, edges_y], s=1000, color=\"black\", marker=\"|\", zorder=1)  # d_alpha[l_edge], d_alpha[r_edge]\n",
    "\n",
    "    start_time = time.time()\n",
    "    coef=1.\n",
    "    x = get_d1_crosses(d_alpha_f, d_alpha_d2f, l_edge, r_edge, d1_coef=coef)\n",
    "    print(f\"\\n------\\n------\\n\\n{ind + 1}/{res_slices_edges.shape[0]} - Slice ({l_edge/1e3}, {r_edge/1e3}) ms - mark: {res_slices_marks[ind]} (1 - dELM, 2 - LCO, 3 - EHO) - {len(x)} peaks - {(time.time() - start_time)*1e3:.3f} ms\")\n",
    "    # axs[0].scatter(x, d_alpha[x], s=20, color=\"black\")\n",
    "\n",
    "    if len(x) > 1:\n",
    "        print(f\"Start prossecing peaks ...\", end=\" \")  # \n",
    "        start_time = time.time()\n",
    "        res_groups_peaks = get_groups_from_signal(d_alpha, d_alpha_f, d_alpha_d2f, l_edge, r_edge)\n",
    "        # print(\"- logg: \", res_groups_peaks)\n",
    "        print(f\"- Tooks: {(time.time() - start_time)*1e3:.3f} ms\")\n",
    "        for g_i in range(len(res_groups_peaks)):\n",
    "            points = res_groups_peaks[g_i]\n",
    "            c = colors[g_i % len(colors)]\n",
    "            axs[0].scatter(points, d_alpha[points] + g_i * 0.05, s=20, color=c, zorder=0)\n",
    "            \n",
    "            m_d = get_time_delta(points) / 1e3\n",
    "            std_d = 0\n",
    "\n",
    "\n",
    "            for p_i in range(1, len(points)):\n",
    "                std_d += (m_d - (points[p_i] - points[p_i - 1]) / 1e3) ** 2\n",
    "            std_d = (std_d / len(points) / (len(points) - 1)) ** .5\n",
    "            print(f\"{g_i + 1}/{len(res_groups_peaks)} Group of peaks [{np.argwhere(x == points[0])[0, 0]}-{np.argwhere(x == points[-1])[0, 0]}] ({c}) - {len(points)} peaks in group - mean delta: {m_d:.3f} ms - freq: {1/m_d:.3f} +- {std_d/(m_d ** 2):.3f} kHz\")\n",
    "        \n",
    "        for p_i in range(len(x)):\n",
    "            num = p_i\n",
    "            d = 0\n",
    "            while num > 10:\n",
    "                num = num // 10\n",
    "                d += 1\n",
    "            axs[0].annotate(p_i, (x[p_i] - (25) * (r_edge - l_edge) / 5000 - 15 * d, d_alpha[x[p_i]] + 0.03))\n",
    "            for ax in axs:\n",
    "                ax.axvline(x[p_i], linestyle=':', color='k', alpha=0.7)\n",
    "    elif len(x) == 1:\n",
    "        axs[0].annotate(0, (x[0] - (25) * (r_edge - l_edge) / 5000 - 15 * d, d_alpha[x[0]] + 0.03))\n",
    "        axs[0].scatter(x, d_alpha[x], s=20, color=\"black\")\n",
    "        for ax in axs:\n",
    "            ax.axvline(x[0], linestyle=':', color='k', alpha=0.7)\n",
    "\n",
    "    for i in channels[::2]:  # channels[::2]\n",
    "        time_mask = np.array((dbs_df.t * 1e6 >= plot_l_edge) & (dbs_df.t * 1e6 <= plot_r_edge))\n",
    "        axs[1].plot(np.linspace(plot_l_edge, plot_r_edge, np.count_nonzero(time_mask)), normalize(dbs_df[f\"ch{i}\"].to_numpy()[:,np.newaxis], axis=0).ravel()[time_mask], label=f\"ch{i}\", alpha=0.8)\n",
    "        axs[2].plot(np.linspace(plot_l_edge, plot_r_edge, np.count_nonzero(time_mask)), normalize(dbs_df[f\"ch{i + 1}\"].to_numpy()[:,np.newaxis], axis=0).ravel()[time_mask], label=f\"ch{i}\", alpha=0.8)\n",
    "        axs[3].plot(np.linspace(plot_l_edge, plot_r_edge, np.count_nonzero(time_mask)), dbs_df[f\"ch{i}_A\"][time_mask], label=f\"ch{i}\")  # filt_signal(\n",
    "        axs[4].plot(np.linspace(plot_l_edge, plot_r_edge, np.count_nonzero(time_mask)), dbs_df[f\"ch{i}_dfi\"][time_mask], label=f\"ch{i}\", alpha=0.8)\n",
    "\n",
    "    axs[-4].plot(range(plot_l_edge, plot_r_edge), df.mhd4[plot_l_edge:plot_r_edge], label=\"MHD 4\")\n",
    "    axs[-4].plot(range(plot_l_edge, plot_r_edge), smooth_steklov(df.mhd4.to_numpy(), 100)[plot_l_edge:plot_r_edge], label=\"Smooth MHD 4\")\n",
    "\n",
    "    axs[-3].plot(range(plot_l_edge, plot_r_edge), mhd[plot_l_edge:plot_r_edge], label=\"Abs MHD\")\n",
    "    axs[-3].plot(range(plot_l_edge, plot_r_edge), smooth_steklov(mhd, 100)[plot_l_edge:plot_r_edge], label=\"Smooth abs MHD\")\n",
    "\n",
    "    axs[-2].plot(range(plot_l_edge, plot_r_edge), df.nl[plot_l_edge:plot_r_edge], label=\"NL\")\n",
    "    axs[-2].plot(range(plot_l_edge, plot_r_edge), smooth_steklov(df.nl.to_numpy(), 100)[plot_l_edge:plot_r_edge], label=\"Smooth NL\")\n",
    "\n",
    "    axs[-1].plot(range(plot_l_edge, plot_r_edge), sxr[plot_l_edge:plot_r_edge], label=\"SXR\")\n",
    "    axs[-1].plot(range(plot_l_edge, plot_r_edge), smooth_steklov(sxr, 100)[plot_l_edge:plot_r_edge], label=\"Smooth SXR\")\n",
    "\n",
    "    plot_ylabels = [r\"$D_\\alpha$\", \"DBS I\", \"DBS Q\", \"DBS A\", r\"DBS $\\partial\\phi$\", \"MHD 4\", \"Abs rad&vert MHD\", \"Nl\", \"SXR\"]  # \n",
    "    for ax_i, ax in enumerate(axs):\n",
    "        ax.set_ylabel(plot_ylabels[ax_i])\n",
    "        ax.grid(which='major', color='#DDDDDD', linewidth=0.9)\n",
    "        ax.grid(which='minor', color='#DDDDDD', linestyle=':', linewidth=0.7)\n",
    "        ax.minorticks_on()\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator(10))\n",
    "        ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    mode = input(\"Input mode [manual (input points) - 0 | auto (input group) - 1 | continue - -1]: \")\n",
    "    while mode != \"\" and int(mode) >= 0:\n",
    "        mode = int(mode)\n",
    "        if mode == 0:\n",
    "            points_ind = list(map(int, input(\"Input point indexes:\\n\").strip().split()))\n",
    "            points = x[points_ind]\n",
    "        else:\n",
    "            gr_ind = int(input(f\"Input group number (from 1 to {len(res_groups_peaks)}): \").strip().split()[0]) - 1\n",
    "            points = res_groups_peaks[gr_ind]\n",
    "\n",
    "        # mean delta in group\n",
    "        m_d = get_time_delta(points) / 1e3\n",
    "\n",
    "        # delta std\n",
    "        std_d = 0\n",
    "        for p_i in range(len(points)):\n",
    "            if p_i > 0:\n",
    "                std_d += (m_d - (points[p_i] - points[p_i - 1]) / 1e3) ** 2\n",
    "        std_d = (std_d / len(points) / (len(points) - 1)) ** .5\n",
    "\n",
    "        print(f\"Group stats: n: {len(points)}, fr: ({1/m_d:.3f} +- {std_d/(m_d ** 2):.3f}) kHZ\")\n",
    "        \n",
    "        mark = input(\"Input mark of the group (string: eho|lco|delm)\")\n",
    "        \n",
    "        df_groups_arr.append([points[0] - 50, points[-1] + 50, len(points), 1/m_d, std_d/(m_d ** 2), mark])\n",
    "\n",
    "        for p in points:\n",
    "            df_points_arr.append([df.t[p], 1 / m_d, mark])\n",
    "            \n",
    "        print(\"------\")\n",
    "        mode = input(\"Input mode [manual (input points) - 0 | auto (input group) - 1 | continue - -1]: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot 44170\n",
      "----\n",
      "Samples (total: 88): EHO - 37, LCO - 19, dELM - 32\n",
      "Groups (total: 24): EHO - 6, LCO - 6, dELM - 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shot {F_ID}\\n----\")\n",
    "print(f\"Samples (total: {len(df_points_arr)}): EHO - {np.count_nonzero(np.array(df_points_arr)[:, 2] == 'eho')}, LCO - {np.count_nonzero(np.array(df_points_arr)[:, 2] == 'lco')}, dELM - {np.count_nonzero(np.array(df_points_arr)[:, 2] == 'delm')}\")\n",
    "print(f\"Groups (total: {len(df_groups_arr)}): EHO - {np.count_nonzero(np.array(df_groups_arr)[:, -1] == 'eho')}, LCO - {np.count_nonzero(np.array(df_groups_arr)[:, -1] == 'lco')}, dELM - {np.count_nonzero(np.array(df_groups_arr)[:, -1] == 'delm')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_edge, r_edge, n, fr, fr std\n",
    "gr_df = pd.DataFrame(sorted(df_groups_arr, key=lambda x: x[0]), columns=[\"l_edge\", \"r_edge\", \"n\", \"fr\", \"fr_std\", \"mark\"])\n",
    "p_df = pd.DataFrame(sorted(df_points_arr, key=lambda x: x[0]), columns=[\"timepoint, ms\", \"fr, kHz\", \"mark\"])\n",
    "\n",
    "gr_df.to_csv(f\"data/df/stats/groups/{F_ID}_groups_stats.csv\", index=False)\n",
    "p_df.to_csv(f\"data/df/stats/samples/{F_ID}_points_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_edge</th>\n",
       "      <th>r_edge</th>\n",
       "      <th>n</th>\n",
       "      <th>fr</th>\n",
       "      <th>fr_std</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164202</td>\n",
       "      <td>165528</td>\n",
       "      <td>5</td>\n",
       "      <td>3.262643</td>\n",
       "      <td>0.114376</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166611</td>\n",
       "      <td>167338</td>\n",
       "      <td>3</td>\n",
       "      <td>3.189793</td>\n",
       "      <td>0.179170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167588</td>\n",
       "      <td>168519</td>\n",
       "      <td>3</td>\n",
       "      <td>2.406739</td>\n",
       "      <td>0.021738</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168786</td>\n",
       "      <td>170025</td>\n",
       "      <td>6</td>\n",
       "      <td>4.389816</td>\n",
       "      <td>0.267177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168786</td>\n",
       "      <td>170268</td>\n",
       "      <td>7</td>\n",
       "      <td>4.341534</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l_edge  r_edge  n        fr    fr_std  mark\n",
       "0  164202  165528  5  3.262643  0.114376     2\n",
       "1  166611  167338  3  3.189793  0.179170     2\n",
       "2  167588  168519  3  2.406739  0.021738     2\n",
       "3  168786  170025  6  4.389816  0.267177     2\n",
       "4  168786  170268  7  4.341534  0.224523     2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_slices_df = pd.read_csv(proj_path + f\"/data/df/stats/{F_ID}_slices_stats.csv\")\n",
    "res_slices_edges = res_slices_df.to_numpy()[:, :2].astype(np.int64)\n",
    "res_slices_marks = res_slices_df.to_numpy()[:, -1].astype(np.int64)\n",
    "# print(len(res_slices_edges))\n",
    "res_slices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_df = pd.read_csv(proj_path + f\"/data/df/marks/{F_ID}_marks.csv\")\n",
    "slices_edges = slices_df.to_numpy()[:, :2]\n",
    "slices_marks = slices_df.to_numpy()[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
