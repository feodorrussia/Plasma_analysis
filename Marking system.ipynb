{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T19:20:17.620063Z",
     "start_time": "2024-09-03T19:20:13.681373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shtRipper v1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from source.Files_operating import read_sht_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:03:23.085308Z",
     "start_time": "2024-09-03T20:03:18.847518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>d_alpha</th>\n",
       "      <th>sxr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "      <td>393216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.196608</td>\n",
       "      <td>0.281714</td>\n",
       "      <td>0.386184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113512</td>\n",
       "      <td>0.393401</td>\n",
       "      <td>0.503047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.388535</td>\n",
       "      <td>-0.076685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.098304</td>\n",
       "      <td>0.012781</td>\n",
       "      <td>0.107358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.196607</td>\n",
       "      <td>0.066460</td>\n",
       "      <td>0.109915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.294911</td>\n",
       "      <td>0.575134</td>\n",
       "      <td>0.439658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.393215</td>\n",
       "      <td>4.818347</td>\n",
       "      <td>2.356772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t        d_alpha            sxr\n",
       "count  393216.000000  393216.000000  393216.000000\n",
       "mean        0.196608       0.281714       0.386184\n",
       "std         0.113512       0.393401       0.503047\n",
       "min         0.000000      -0.388535      -0.076685\n",
       "25%         0.098304       0.012781       0.107358\n",
       "50%         0.196607       0.066460       0.109915\n",
       "75%         0.294911       0.575134       0.439658\n",
       "max         0.393215       4.818347       2.356772"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_ID = 44184\n",
    "dir_path = \"C:/Users/f.belous/Work/Projects/Plasma_analysis/data/sht/G-ELM/\"  # D:/Edu/Lab/Projects/Plasma_analysis/data/sht/G-ELM/\n",
    "\n",
    "df = read_sht_data(f'sht{F_ID}', dir_path)\n",
    "df = df.rename(columns={\"ch1\": \"d_alpha\"})\n",
    "df[\"sxr\"] = read_sht_data(f'sht{F_ID}', dir_path, data_name=\"SXR 50 mkm\").ch1\n",
    "# dbs = read_dataFile(f'data/dbs/{F_ID} DBS.dat')\n",
    "# mgd_data_1\n",
    "# mgd_data_3\n",
    "# mgd_data_2\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:04:45.860846Z",
     "start_time": "2024-09-03T20:04:45.836461Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d_alpha = df.d_alpha.to_numpy()\n",
    "sxr = df.sxr.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:04:45.860846Z",
     "start_time": "2024-09-03T20:04:45.836461Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d_alpha_d1 = np.diff(d_alpha)\n",
    "sxr_d1 = np.diff(sxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "b, a = signal.butter(5, 0.1)\n",
    "d_alpha_f = signal.filtfilt(b, a, d_alpha_d1)\n",
    "sxr_f = signal.filtfilt(b, a, sxr_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:10:59.964319Z",
     "start_time": "2024-09-03T20:10:59.950218Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "da_f_q, da_f_std = np.quantile(d_alpha_f, 0.9), d_alpha_f.std()\n",
    "sxr_f_q, sxr_f_std = np.quantile(sxr_f, 0.9), sxr_f.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T20:17:48.361500Z",
     "start_time": "2024-09-03T20:17:48.341926Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23383257112357403 0.0025870038350616488 (2582,)\n",
      "0.015201329800146266 0.0009320451522782375 (1080,)\n"
     ]
    }
   ],
   "source": [
    "indexes_da = np.round(df.t.to_numpy()[:-1][abs(d_alpha_f - np.quantile(d_alpha_f, 0.9)) > d_alpha_f.std() * 3] * 1e6)\n",
    "indexes_sxr = np.round(df.t.to_numpy()[:-1][abs(sxr_f - np.quantile(sxr_f, 0.9)) > sxr_f.std() * 6] * 1e6)\n",
    "\n",
    "print(da_f_q, da_f_std, indexes_da.shape)\n",
    "print(sxr_f_q, sxr_f_std, indexes_sxr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(indexes_da.shape[0]):\n",
    "    if indexes_da[i] in indexes_sxr:\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_boarders(data: np.array, scale=1.5):\n",
    "    loc_max_ind = np.argmax(data)\n",
    "    dist_ind = np.argsort(np.abs(data - data[loc_max_ind] / scale))\n",
    "    return [dist_ind[dist_ind <= loc_max_ind][0], dist_ind[dist_ind >= loc_max_ind][0]]\n",
    "\n",
    "\n",
    "class Slice:\n",
    "    def __init__(self, start_index=0, end_index=0):\n",
    "        self.l = start_index\n",
    "        self.r = end_index\n",
    "\n",
    "    def set_boarders(self, start_index: int, end_index: int) -> None:\n",
    "        self.l = start_index\n",
    "        self.r = end_index\n",
    "\n",
    "    def copy(self, other):\n",
    "        self.l = other.l\n",
    "        self.r = other.r\n",
    "\n",
    "    def check_length(self, len_edge: int) -> bool:\n",
    "        return self.r - self.l > len_edge\n",
    "\n",
    "    def check_dist(self, other, dist_edge: int) -> bool:\n",
    "        return other.l - self.r > dist_edge\n",
    "\n",
    "    def collide_slices(self, other, dist_edge: int) -> bool:\n",
    "        if not self.check_dist(other, dist_edge):\n",
    "            self.r = other.r\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def step(self):\n",
    "        self.r += 1\n",
    "\n",
    "    def collapse_boarders(self):\n",
    "        self.l = self.r\n",
    "\n",
    "    def is_null(self) -> bool:\n",
    "        return self.l == self.r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mark_data = np.zeros(d_alpha_f.shape)\n",
    "mark_data[abs(d_alpha_f - np.quantile(d_alpha_f, 0.9)) > d_alpha_f.std() * 3] += 1\n",
    "mark_data[abs(sxr_f - np.quantile(sxr_f, 0.9)) > sxr_f.std() * 6] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = df.t.to_numpy()\n",
    "\n",
    "scale = 1.5\n",
    "length_edge = 10\n",
    "distance_edge = 10\n",
    "step_out = 10\n",
    "\n",
    "proc_slice = Slice(0, 0)\n",
    "cur_slice = Slice(0, 1)\n",
    "f_fragment = False\n",
    "\n",
    "while cur_slice.r < mark_data.shape[0]:\n",
    "    if mark_data[cur_slice.r] == 1.0:\n",
    "        if not f_fragment:\n",
    "            f_fragment = True\n",
    "    elif f_fragment:\n",
    "        # print(start_ind, end_ind)\n",
    "        if scale <= 1:\n",
    "            if not cur_slice.check_length(length_edge):\n",
    "                mark_data[cur_slice.l: cur_slice.r] = 0.0\n",
    "            elif not proc_slice.collide_slices(cur_slice, distance_edge):\n",
    "                mark_data[proc_slice.l: proc_slice.r] = 1.0\n",
    "                proc_slice.copy(cur_slice)\n",
    "        elif scale:\n",
    "            mark_data[cur_slice.l: cur_slice.r] = 0.0\n",
    "            if cur_slice.check_length(length_edge):\n",
    "                boarders = get_boarders(data[cur_slice.l: cur_slice.r], scale)\n",
    "                # print(boards)\n",
    "                boarders[0] = max(boarders[0] + cur_slice.l - step_out, 0)\n",
    "                boarders[1] = min(boarders[1] + cur_slice.l, mark_data.shape[0])\n",
    "\n",
    "                mark_data[boarders[0]:boarders[1]] = 1.0\n",
    "\n",
    "        f_fragment = False\n",
    "        cur_slice.collapse_boarders()\n",
    "    elif not f_fragment:\n",
    "        cur_slice.collapse_boarders()\n",
    "        if proc_slice.is_null():\n",
    "            proc_slice.copy(cur_slice)\n",
    "\n",
    "    cur_slice.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_fragments(data: np.array, mark_data: np.array, length_edge=10, distance_edge=25, scale=1.5, step_out=10) -> np.array:\n",
    "    proc_slice = Slice(0, 0)\n",
    "    cur_slice = Slice(0, 1)\n",
    "    f_fragment = False\n",
    "\n",
    "    while cur_slice.r < mark_data.shape[0]:\n",
    "        if mark_data[cur_slice.r] == 1.0:\n",
    "            if not f_fragment:\n",
    "                f_fragment = True\n",
    "        elif f_fragment:\n",
    "            # print(start_ind, end_ind)\n",
    "            if scale <= 1:\n",
    "                if not cur_slice.check_length(length_edge):\n",
    "                    mark_data[cur_slice.l: cur_slice.r] = 0.0\n",
    "                elif not proc_slice.collide_slices(cur_slice, distance_edge):\n",
    "                    mark_data[proc_slice.l: proc_slice.r] = 1.0\n",
    "                    proc_slice.copy(cur_slice)\n",
    "            elif scale:\n",
    "                mark_data[cur_slice.l: cur_slice.r] = 0.0\n",
    "                if cur_slice.check_length(length_edge):\n",
    "                    boarders = get_boarders(data[cur_slice.l: cur_slice.r], scale)\n",
    "                    # print(boards)\n",
    "                    boarders[0] = max(boarders[0] + cur_slice.l - step_out, 0)\n",
    "                    boarders[1] = min(boarders[1] + cur_slice.l, mark_data.shape[0])\n",
    "\n",
    "                    mark_data[boarders[0]:boarders[1]] = 1.0\n",
    "\n",
    "            f_fragment = False\n",
    "            cur_slice.collapse_borders()\n",
    "        elif not f_fragment:\n",
    "            cur_slice.collapse_borders()\n",
    "            if proc_slice.is_null():\n",
    "                proc_slice.copy(cur_slice)\n",
    "\n",
    "        cur_slice.step()\n",
    "\n",
    "    return mark_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "mode_plotting = 1  # int(input(\"Input visualising mode [ 0 - manual | 1 - only marked ]:\"))\n",
    "# mode_marking = int(input(\"Input marking mode (0 - manual | 1 - semiauto): \").strip().split()[0])\n",
    "l_edge = 184000  # int(input(f\"Input start index [0:{df.shape[0]//1000*1000}]: \").strip().split()[0])\n",
    "# print(\"---\")\n",
    "step = 2000\n",
    "width = 3000\n",
    "\n",
    "new_ind_da = indexes_da[indexes_da * 1e6 >= l_edge]\n",
    "new_ind_sxr = indexes_sxr[indexes_sxr * 1e6 >= l_edge]\n",
    "\n",
    "step_away = 10\n",
    "ind_ind = [0, 0]\n",
    "\n",
    "while l_edge < df.shape[0]:\n",
    "    r_edge = min(l_edge + width, df.shape[0] - 1)\n",
    "\n",
    "    slice_da_indexes = []\n",
    "    while ind_ind[0] < new_ind_da.shape[0] and l_edge <= int(new_ind_da[ind_ind[0]] * 1e6) <= r_edge:\n",
    "        slice_da_indexes.append(new_ind_da[ind_ind[0]])\n",
    "        ind_ind[0] += 1\n",
    "        \n",
    "    slice_sxr_indexes = []\n",
    "    while ind_ind[1] < new_ind_sxr.shape[0] and l_edge <= new_ind_sxr[ind_ind[1]] * 1e6 <= r_edge:\n",
    "        slice_sxr_indexes.append(new_ind_sxr[ind_ind[1]])\n",
    "        ind_ind[1] += 1\n",
    "    \n",
    "    if mode_plotting == 1 and len(slice_da_indexes) == 0 and len(slice_sxr_indexes) == 0:\n",
    "        l_edge += step\n",
    "        continue\n",
    "    \n",
    "    fig, [ax1, ax2] = plt.subplots(2, 1)\n",
    "\n",
    "    fig.set_figwidth(16)\n",
    "    fig.set_figheight(8)\n",
    "\n",
    "    ax1.plot(range(l_edge, r_edge), d_alpha[l_edge:r_edge], label=\"D-alpha\")\n",
    "    ax1.plot(range(l_edge, r_edge), d_alpha_d1[l_edge:r_edge], label=\"Diff 1\")\n",
    "    ax1.plot(range(l_edge, r_edge), d_alpha_f[l_edge:r_edge], label=\"Filter\")\n",
    "    for ind in slice_da_indexes:\n",
    "        ax1.axvline(int(ind * 1e6), color=\"green\", linestyle=':', linewidth=0.7)\n",
    "\n",
    "    ax1.grid(which='major', color='#DDDDDD', linewidth=0.9)\n",
    "    ax1.grid(which='minor', color='#DDDDDD', linestyle=':', linewidth=0.7)\n",
    "    ax1.minorticks_on()\n",
    "    ax1.xaxis.set_minor_locator(AutoMinorLocator(10))\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(range(l_edge, r_edge), sxr[l_edge:r_edge], label=\"SXR\")\n",
    "    ax2.plot(range(l_edge, r_edge), sxr_d1[l_edge:r_edge], label=\"Diff 1\")\n",
    "    ax2.plot(range(l_edge, r_edge), sxr_f[l_edge:r_edge], label=\"Filter\")\n",
    "    for ind in slice_sxr_indexes:\n",
    "        ax2.axvline(int(ind * 1e6), color=\"green\", linestyle=':', linewidth=0.7)\n",
    "\n",
    "    ax2.grid(which='major', color='#DDDDDD', linewidth=0.9)\n",
    "    ax2.grid(which='minor', color='#DDDDDD', linestyle=':', linewidth=0.7)\n",
    "    ax2.minorticks_on()\n",
    "    ax2.xaxis.set_minor_locator(AutoMinorLocator(10))\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # res = list(map(int, input(f\"Input index pairs of ELM fragments ({df.t[l_edge]} - {df.t[r_edge]} ms):\\n\").strip().split()))\n",
    "    # for i in range(0, len(res), 2):\n",
    "    #     board_ind = [res[i], res[i+1]]\n",
    "\n",
    "    #     mark = float(input(\"Input mark to set [ 0 | 1 | 2 ]: \"))\n",
    "        \n",
    "    #     if mode_marking and mark > 0:\n",
    "    #         board_ind = get_borders(df.loc[res[i]:res[i + 1], \"ch1\"].to_numpy(), scale=1.5)\n",
    "    #         board_ind[0] = max(board_ind[0] - step_away + res[i], 0)\n",
    "    #         board_ind[1] += res[i]\n",
    "        \n",
    "    #     df.loc[board_ind[0]:board_ind[1], \"ch1_marked\"] = mark\n",
    "    input(f\"ELM fragment ({df.t[l_edge]} - {df.t[r_edge]} ms)\\n\")\n",
    "\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    l_edge += step\n",
    "\n",
    "# 217500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
